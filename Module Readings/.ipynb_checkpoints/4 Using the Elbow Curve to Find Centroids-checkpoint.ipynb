{
 "cells": [
  {
   "cell_type": "raw",
   "id": "intelligent-gothic",
   "metadata": {},
   "source": [
    "18.4.1 Elbow Curve\n",
    "\n",
    "\n",
    "The trial-and-error method seemed to work to an extent, but the two of you wonder what happens when data gets more complex, such as in the cryptocurrency dataset.\n",
    "\n",
    "There is a method that will help you make a more educated guess on the amount of clusters called the elbow curve."
   ]
  },
  {
   "cell_type": "raw",
   "id": "greek-donna",
   "metadata": {},
   "source": [
    "An easy method for determining the best number for K is the elbow curve. Elbow curves get their names from their shape: they turn on a specific value, which looks a bit like an elbow!\n",
    "\n",
    "To create an elbow curve, we'll plot the clusters on the x-axis and the values of a selected objective function on the y-axis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "powerful-discovery",
   "metadata": {},
   "source": [
    "Inertia is one of the most common objective functions to use when creating an elbow curve. While what it's actually doing can get into some pretty complicated math, basically the inertia objective function is measuring the amount of variation in the dataset.\n",
    "\n",
    "So, for our elbow curve, we'll plot the number of clusters (also known as the values of K) on the x-axis and the inertia values on the y-axis.\n",
    "\n",
    "Let's see what happens when we plot our K values versus inertia for the preprocessed iris dataset created earlier.\n",
    "\n",
    "We will first take a look at the elbow curve using this dataset, since we know that there should be three clusters."
   ]
  },
  {
   "cell_type": "raw",
   "id": "enabling-sponsorship",
   "metadata": {},
   "source": [
    "Let's first take a look at the elbow curve using the iris dataset, since we know that there should be three clusters:\n",
    "\n",
    "# Initial imports\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "import hvplot.pandas\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "animal-harmony",
   "metadata": {},
   "source": [
    "Then enter the code to load in the dataset into a DataFrame:\n",
    "\n",
    "# Loading data\n",
    "file_path = \"Resources/new_iris_data.csv\"\n",
    "df_iris = pd.read_csv(file_path)\n",
    "\n",
    "df_iris.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ancient-optics",
   "metadata": {},
   "source": [
    "Store Values of K to Plot\n",
    "\n",
    "We'll start with creating an empty list to hold inertia values. We'll also store a range of K values we want to test. Enter the code in a new cell:\n",
    "\n",
    "inertia = []\n",
    "k = list(range(1, 11))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "lightweight-token",
   "metadata": {},
   "source": [
    "Loop Through K  Values and Find Inertia\n",
    "\n",
    "Next, we'll loop through each K value, find the inertia, and store it into our list. Enter the code in the next cell:\n",
    "\n",
    "# Looking for the best K\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(df_iris)\n",
    "    inertia.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "worldwide-prayer",
   "metadata": {},
   "source": [
    "Create a DataFrame and Plot the Elbow Curve\n",
    "We'll create a DataFrame that stores our K values and their appropriate inertia values. This will allow for an easy plot of the results withhvplot. In another new cell, enter the code:\n",
    "\n",
    "\n",
    "# This will create a graph.\n",
    "# Define a DataFrame to plot the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow.hvplot.line(x=\"k\", y=\"inertia\", title=\"Elbow Curve\", xticks=k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "super-norfolk",
   "metadata": {},
   "source": [
    "Use the Elbow Curve to Determine the Best K Value\n",
    "\n",
    "Let's take a look at the graph.\n",
    "\n",
    "Note the shape of the curve on the following graph. At point 0 (top left), the line starts as a steep vertical slope that breaks at point 2, shifts to a slightly horizontal slope, breaks again at point 3, then shifts to a strong horizontal line that reaches to point 10. The angle at point 3 looks like an elbow, which gives this type of curve its name:\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "caring-rogers",
   "metadata": {},
   "source": [
    "18.4.2 Use the Elbow Curve\n",
    "\n",
    "Let's walk through an example of how to use the elbow curve. This time, we'll answer the question from the previous section on customer data and how many clusters would be ideal.\n",
    "\n",
    "Open a new notebook and import our dependencies:\n",
    "\n",
    "# Initial imports\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "raw",
   "id": "combined-compatibility",
   "metadata": {},
   "source": [
    "Then enter the code to load in the dataset into a DataFrame:\n",
    "\n",
    "# Load data\n",
    "file_path = \"Resources/shopping_data_cleaned.csv\"\n",
    "df_shopping = pd.read_csv(file_path)\n",
    "df_shopping.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "joint-shooting",
   "metadata": {},
   "source": [
    "To create the elbow curve, remember there are two values we need: a list of K values and a list of inertia values. Recall that inertia is the objective function to plot K values against. We will loop through 10 values for K and determine the inertia:\n",
    "\n",
    "inertia = []\n",
    "k = list(range(1, 11))\n",
    "# Calculate the inertia for the range of K values\n",
    "for i in k:\n",
    "   km = KMeans(n_clusters=i, random_state=0)\n",
    "   km.fit(df_shopping)\n",
    "   inertia.append(km.inertia_)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "designed-preference",
   "metadata": {},
   "source": [
    "Next, let's create a plot for the elbow curve:\n",
    "\n",
    "# Define a DataFrame to plot the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "elbow_data\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ethical-schedule",
   "metadata": {},
   "source": [
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow.hvplot.line(x=\"k\", y=\"inertia\", title=\"Elbow Curve\", xticks=k)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "looking-gardening",
   "metadata": {},
   "source": [
    "This elbow curve doesn't have as obvious of an elbow as previously seen. \n",
    "\n",
    "Either K values for points 5 or 6 could be considered the elbow. \n",
    "\n",
    "There is no surefire way to pick between the two, but we did knock down the potential number of K values between points from 10 to 2. \n",
    "\n",
    "You might also wonder why point 3 wasn't considered. \n",
    "\n",
    "Remember, we're looking for the break where the vertical direction shifts to a strong horizontal direction. \n",
    "\n",
    "Compared to points 5 and 6, the shift at point 3 isn't as dramatic."
   ]
  },
  {
   "cell_type": "raw",
   "id": "imposed-occasions",
   "metadata": {},
   "source": [
    "Before plotting the two K values, let's create a K-means function again to reuse the K-means cluster. As you may recall, functions allow us to save time because we don't need to write the code contained in the function more than once:\n",
    "\n",
    "def get_clusters(k, data):\n",
    "   # Create a copy of the DataFrame\n",
    "   data = data.copy()\n",
    "\n",
    "   # Initialize the K-Means model\n",
    "   model = KMeans(n_clusters=k, random_state=0)\n",
    "\n",
    "   # Fit the model\n",
    "   model.fit(data)\n",
    "\n",
    "   # Predict clusters\n",
    "   predictions = model.predict(data)\n",
    "\n",
    "   # Create return DataFrame with predicted clusters\n",
    "   data[\"class\"] = model.labels_\n",
    "\n",
    "   return data\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bridal-success",
   "metadata": {},
   "source": [
    "Creating a function is not required for K-means. The get_clusters function helps us save time since we'll run the algorithm twice: once with point 5 and again with point 6. If you're still struggling with functions, feel free to run the code twice, but do revisit using get_clusters after strengthening your Python function skills."
   ]
  },
  {
   "cell_type": "raw",
   "id": "associate-wallpaper",
   "metadata": {},
   "source": [
    "run the function for K = 5:\n",
    "\n",
    "five_clusters = get_clusters(5, df_shopping)\n",
    "five_clusters.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "hollywood-channel",
   "metadata": {},
   "source": [
    "run the function for K = 6:\n",
    "\n",
    "six_clusters = get_clusters(6, df_shopping)\n",
    "six_clusters.head()# "
   ]
  },
  {
   "cell_type": "raw",
   "id": "extreme-reaction",
   "metadata": {},
   "source": [
    "# Plotting the 2D-Scatter with x=\"Annual_Income\" and y=\"Spending_Score\"\n",
    "five_clusters.hvplot.scatter(x=\"Annual_Income\", y=\"Spending_Score\", by=\"class\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "juvenile-norwegian",
   "metadata": {},
   "source": [
    "# Plot the 3D-scatter with x=\"Annual Income\", y=\"Spending Score (1-100)\" and z=\"Age\"\n",
    "fig = px.scatter_3d(\n",
    "    five_clusters,\n",
    "    x=\"Age\",\n",
    "    y=\"Spending_Score\",\n",
    "    z=\"Annual_Income\",\n",
    "    color=\"class\",\n",
    "    symbol=\"class\",\n",
    "    width=800,\n",
    ")\n",
    "fig.update_layout(legend=dict(x=0, y=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "located-address",
   "metadata": {},
   "source": [
    "# Plot a 2D graph for K = 6:\n",
    "\n",
    "# Plotting the 2D-Scatter with x=\"Annual_Income\" and y=\"Spending_Score\"\n",
    "six_clusters.hvplot.scatter(x=\"Annual_Income\", y=\"Spending_Score\", by=\"class\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "concrete-isolation",
   "metadata": {},
   "source": [
    "\n",
    "# Plotting the 3D-Scatter with x=\"Annual Income\", y=\"Spending Score (1-100)\" and z=\"Age\"\n",
    "fig = px.scatter_3d(\n",
    "    six_clusters,\n",
    "    x=\"Age\",\n",
    "    y=\"Spending_Score\",\n",
    "    z=\"Annual_Income\",\n",
    "    color=\"class\",\n",
    "    symbol=\"class\",\n",
    "    width=800,\n",
    ")\n",
    "fig.update_layout(legend=dict(x=0, y=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "auburn-atlanta",
   "metadata": {},
   "source": [
    "Recall, in the trial-and-error method, both graphs displayed multiple clusters. We're still applying some trial and error here, but the elbow curve helps narrow down the number of clusters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "compound-hanging",
   "metadata": {},
   "source": [
    "Now, the important question: So do we use five or six groups? This depends on what insights you can take away from the data. One might conclude that six groups would be most useful because they could be broken down like so:\n",
    "\n",
    "Cluster 0: medium income, low annual spend\n",
    "Cluster 1: low income, low annual spend\n",
    "Cluster 2: high income, low annual spend\n",
    "Cluster 3: low income, high annual spend\n",
    "Cluster 4: medium income, high annual spend\n",
    "Cluster 5: very high income, high annual spend"
   ]
  },
  {
   "cell_type": "raw",
   "id": "quality-norway",
   "metadata": {},
   "source": [
    "If we choose five groups, they would need to be different and would not fit into what you're looking for, which is grouping types of customers based on spending habits.\n",
    "\n",
    "Remember, unsupervised learning can help us make decisions about the data, up to a point, then it is up to you, the expert, to make the final call.\n",
    "\n",
    "So far, you've learned that when dealing with multiple features, the clusters were best viewed in 3D graphs, which can get messy. In the next section, we'll learn how to limit or combine features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
