{
 "cells": [
  {
   "cell_type": "raw",
   "id": "activated-compatibility",
   "metadata": {},
   "source": [
    "18.3.1 Clustering Data\n",
    "\n",
    "Now that you and Martha are asking the right questions about your data and processing it to a state that you feel comfortable with, it's time to put it into action and start clustering!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "realistic-allen",
   "metadata": {},
   "source": [
    "Clustering is a type of unsupervised learning that groups data points together. This group of data points is called a cluster.\n",
    "\n",
    "Imagine you are in a roomful of spheres (data points). You want to learn more about them, so you start to observe them.\n",
    "\n",
    "Every sphere represents a flower, and three axes represent features of flowers. After observing the flowers, you discover patterns when you combine the three features:\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "missing-cartridge",
   "metadata": {},
   "source": [
    "We can see that spheres (data points) with similar features seem to be closer together than data points with dissimilar features. We can use this spatial information to group similar data points together.\n",
    "\n",
    "If you look at the flower features in the graph below, and start to plot them, they'll start to form groups on the graph.\n",
    "\n",
    "After we plot the data points, they start to form three different groups, or clusters:\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "funny-vegetable",
   "metadata": {},
   "source": [
    "18.3.2 K-means Algorithm\n",
    "\n",
    "Clustering is exactly what we want from unsupervised learning, but exactly how can we determine the clusters? Martha knows she needs to group the cryptocurrency data, but she isn't sure how to determine the number of groups to create. One of the most popular ways to cluster is by using the K-means algorithm.\n",
    "\n",
    "K-means is an unsupervised learning algorithm used to identify and solve clustering issues.\n",
    "\n",
    "K represents how many clusters there will be. These clusters are then determined by the means of all the points that will belong to the cluster.\n",
    "\n",
    "The K-means algorithm groups the data into K clusters, where belonging to a cluster is based on some similarity or distance measure to a centroid.\n",
    "\n",
    "A centroid is a data point that is the arithmetic mean position of all the points on a cluster:\n",
    "\n",
    "The centroid is found by taking the mean of all the x values in a cluster, and the mean of all the y values in a cluster."
   ]
  },
  {
   "cell_type": "raw",
   "id": "expired-snake",
   "metadata": {},
   "source": [
    "What would be the centroid to the points (8, 1), (5, 9), (7, 3), and (4,7)?\n",
    "\n",
    "The mean of the x coordinates is 6. \n",
    "8 + 5 + 7 + 4 = 24 and 24 / 4 = 6\n",
    "The mean of the y coordinates is 5. \n",
    "1 + 9 + 3 + 7 = 20 and 20 / 4 = 5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "filled-buffalo",
   "metadata": {},
   "source": [
    "Code along to see how we can use K-means on the iris dataset. To get started, we'll import our libraries as well as the library for the KMeans algorithm from the sklearn library, as shown below:\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import hvplot.pandas\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "raw",
   "id": "sustainable-minutes",
   "metadata": {},
   "source": [
    "After we have imported our library, we'll store the cleaned iris data into a DataFrame:\n",
    "\n",
    "# Loading data\n",
    "file_path = \"Module trainings/new_iris_data.csv\"\n",
    "df_iris = pd.read_csv(file_path)\n",
    "df_iris.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "patent-briefs",
   "metadata": {},
   "source": [
    "Initialize the K Starting Centroids\n",
    "\n",
    "After data has been loaded, create an instance of the K-means algorithm and initialize it with the desired number of clusters (K).\n",
    "\n",
    "We're working with data that has a set number of clusters. Often, you won't know the number that you should work with, so you'll have to use the trial-and-error method to determine it. In the next section, we'll learn an approach that can help with the trial-and-error method.\n",
    "\n",
    "For this example, we know that there are three different classes of iris plants, so we'll use K = 3:\n",
    "\n",
    "# Initializing model with K = 3 (since we already know there are three classes of iris plants)\n",
    "model = KMeans(n_clusters=3, random_state=5)\n",
    "model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "enclosed-nurse",
   "metadata": {},
   "source": [
    "Data Points Assigned to Nearest Centroid\n",
    "\n",
    "Once the model instance is created, our next step is to fit the model with the unlabeled data. This step should be familiar with fitting data from supervised learning; however, you'll notice that data is not being split into training and test data. When the model is being trained (fit the data), the K-means algorithm will iteratively look for the best centroid for each of the K clusters:\n",
    "\n",
    "# Fitting model\n",
    "model.fit(df_iris)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "impressed-calendar",
   "metadata": {},
   "source": [
    "Group Data Points\n",
    "\n",
    "After the model is fit, the corresponding cluster for every iris plant in the dataset can be found using the predict() method:\n",
    "\n",
    "# Get the predictions\n",
    "predictions = model.predict(df_iris)\n",
    "print(predictions)\n",
    "\n",
    "As you can see, there were three subclasses that were labeled 0, 1, and 2. \n",
    "\n",
    "These are not the means for the centroids, but rather just the label names. The actual naming of the classes is part of the job by a subject matter expert, or whoever performs the analysis, such as yourself. The K-means algorithm is able to identify how many clusters are in the data and label them with numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "pointed-documentation",
   "metadata": {},
   "source": [
    "After we have the class for each data point, we can add a new column to the DataFrame with the predicted classes:\n",
    "\n",
    "# Add a new class column to the df_iris\n",
    "df_iris[\"class\"] = model.labels_\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "medieval-petersburg",
   "metadata": {},
   "source": [
    "Visualize the Results\n",
    "\n",
    "Visualizing the clusters helps to graphically understand how they are arranged. In this case, we actually have too many features to represent visually, but we can select a few of them and plot the clusters.\n",
    "\n",
    "For our visualizations, we'll use hvPlot, a graphing library that allows deeper exploration of the data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "synthetic-sword",
   "metadata": {},
   "source": [
    "We'll import the following dependencies for hvplot, as shown below:\n",
    "\n",
    "import plotly.express as px\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "raw",
   "id": "spare-bookmark",
   "metadata": {},
   "source": [
    "First, look at the data with two features. The hvPlot library makes it easy to create scatter plots directly from a Pandas DataFrame. After our DataFrame has been loaded in from the CSV, we can create a scatter plot with one line of code. We pass in the arguments for the x- and y-axis and color them by class:\n",
    "\n",
    "# Create a scatterplot of df_iris\n",
    "df_iris.hvplot.scatter(x=\"sepal_length\", y=\"sepal_width\", by=\"class\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "regulated-avenue",
   "metadata": {},
   "source": [
    "In the results, it appears some of the clusters are overlapping and not quite forming three distincts groups as we had hoped. \n",
    "\n",
    "Before jumping to the conclusion that our model didn't do what we wanted, remember that we are taking multiple data points (petal_width, sepal_length, and petal_length).\n",
    "\n",
    "Since this plot is on a 2D graph, all three features can't be properly displayed.\n",
    "\n",
    "Plotting in 3D takes a few more arguments and will allow us to visualize more data points. We now have an x-, y-, and z-axis that will take all three of our features as coordinates.\n",
    "\n",
    "We pass in the class data points to determine color and symbol of the points. Size of the points will be determined by sepal_width.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "motivated-queue",
   "metadata": {},
   "source": [
    "Finally, we'll update the figure by passing a dictionary with x, y, and z:\n",
    "\n",
    "# Plotting the clusters with three features\n",
    "fig = px.scatter_3d(df_iris, x=\"petal_width\", y=\"sepal_length\", z=\"petal_length\", color=\"class\", symbol=\"class\", size=\"sepal_width\",width=800)\n",
    "fig.update_layout(legend=dict(x=0,y=1))\n",
    "fig.show()\n",
    "\n",
    "[The 3D scatter plot can be rotated using the mouse to click and drag and panned using the scroll wheel.]{style=\"font-weight: 400;\"}\n",
    "\n",
    "Here, you can see that our model did do what we wanted! There are now three distinct groups that correspond to the three clusters that we expect the model to break the data into."
   ]
  },
  {
   "cell_type": "raw",
   "id": "temporal-majority",
   "metadata": {},
   "source": [
    "18.3.3 Trial and Error of Finding Centroids\n",
    "\n",
    "So far, the value of K we have used was known ahead of time. We knew the amount of classes that were contained in the dataset, and so we set the value appropriately. This will usually not be the case, and the decision will need to be made by looking at the data with a bit of trial and error.\n",
    "\n",
    "To test by trial and error with clusters, we'll use a sample of the shopping dataset that contains customer data.\n",
    "\n",
    "Start by opening a new notebook and enter the code to import the libraries we'll need to use:\n",
    "\n",
    "# Initial imports\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bearing-involvement",
   "metadata": {},
   "source": [
    "Then enter the code to load in the dataset into a DataFrame:\n",
    "\n",
    "# Load data\n",
    "file_path = \"Resources/shopping_data_cleaned.csv\"\n",
    "df_shopping = pd.read_csv(file_path)\n",
    "df_shopping.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "whole-merchandise",
   "metadata": {},
   "source": [
    "See what the points look like at the start by entering the code. (Note: if you completed the SKill Drill in 18.2.5, your column names will be \"AnnualIncome\" and \"SpendingScore\".)\n",
    "\n",
    "df_shopping.hvplot.scatter(x=\"Annual Income\", y=\"Spending Score (1-100)\")\n",
    "\n",
    "On first look, it may seem obvious the amount of clusters that would work, but let's see what happens when we start to cluster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "alternative-hazard",
   "metadata": {},
   "source": [
    "First, let's create a function so we can quickly run K-means on the DataFrame with a different amount of clusters by entering the following code:\n",
    "\n",
    "# Function to cluster and plot dataset\n",
    "def test_cluster_amount(df, clusters):\n",
    "    model = KMeans(n_clusters=clusters, random_state=5)\n",
    "    model\n",
    "\n",
    "    # Fitting model\n",
    "    model.fit(df)\n",
    "\n",
    "    # Add a new class column to df_iris\n",
    "    df[\"class\"] = model.labels_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "breathing-wales",
   "metadata": {},
   "source": [
    "This function will take a DataFrame and the number of clusters to make as arguments. Start by running the function to create two clusters and then plot the results:\n",
    "\n",
    "test_cluster_amount(df_shopping, 2)\n",
    "df_shopping.hvplot.scatter(x=\"Annual Income\", y=\"Spending Score (1-100)\", by=\"class\")\n",
    "\n",
    "At first glance, two clusters look okay with some data points mixed in the middle.\n",
    "\n",
    "Recall that sometimes plotting data with more than two data points in a 2D plot might show the true clustering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "behind-earth",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
